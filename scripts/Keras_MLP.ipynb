{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e1d836-eb5f-47cf-873e-70c5556c75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ca80a59-362d-40dd-b151-a7d34b8293d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv.zip')\n",
    "test = pd.read_csv('../input/test.csv.zip')\n",
    "submission = pd.read_csv('../input/sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c766da0-2b08-4b7c-a007-f23dc925d2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont6     cont7  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B  ...  0.718367  0.335060   \n",
       "1   2    A    B    A    A    A    A    A    A    B  ...  0.438917  0.436585   \n",
       "2   5    A    B    A    A    B    A    A    A    B  ...  0.289648  0.315545   \n",
       "3  10    B    B    A    B    A    A    A    A    B  ...  0.440945  0.391128   \n",
       "4  11    A    B    A    B    A    A    A    A    B  ...  0.178193  0.247408   \n",
       "\n",
       "     cont8    cont9   cont10    cont11    cont12    cont13    cont14     loss  \n",
       "0  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493  0.714843  2213.18  \n",
       "1  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431  0.304496  1283.60  \n",
       "2  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709  0.774425  3005.09  \n",
       "3  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077  0.602642   939.85  \n",
       "4  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57325dc-a581-4be1-8912-bf5fec32820e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.466591</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.377724</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.392562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.51890</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.689039</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.297232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.369930</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.33237</td>\n",
       "      <td>0.31480</td>\n",
       "      <td>0.348867</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.555955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.398862</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>0.359572</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.825823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont5     cont6  \\\n",
       "0   4    A    B    A    A    A    A    A    A    B  ...  0.281143  0.466591   \n",
       "1   6    A    B    A    B    A    A    A    A    B  ...  0.836443  0.482425   \n",
       "2   9    A    B    A    B    B    A    B    A    B  ...  0.718531  0.212308   \n",
       "3  12    A    A    A    A    B    A    A    A    A  ...  0.397069  0.369930   \n",
       "4  15    B    A    A    A    A    B    A    A    A  ...  0.302678  0.398862   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13    cont14  \n",
       "0  0.317681  0.61229  0.34365  0.38016  0.377724  0.369858  0.704052  0.392562  \n",
       "1  0.443760  0.71330  0.51890  0.60401  0.689039  0.675759  0.453468  0.208045  \n",
       "2  0.325779  0.29758  0.34365  0.30529  0.245410  0.241676  0.258586  0.297232  \n",
       "3  0.342355  0.40028  0.33237  0.31480  0.348867  0.341872  0.592264  0.555955  \n",
       "4  0.391833  0.23688  0.43731  0.50556  0.359572  0.352251  0.301535  0.825823  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad66b9e-f5a3-42b1-8762-dd685653fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[33898, 43407, 3458, 100139, 60086, 117290, 89806, 7751, 164059, 143297]\n",
      "Dim train (188318, 1190)\n",
      "Dim test (125546, 1190)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "index = list(train.index)\n",
    "print(index[0:10])\n",
    "np.random.shuffle(index)\n",
    "print(index[0:10])\n",
    "train = train.iloc[index]\n",
    "'train = train.iloc[np.random.permutation(len(train))]'\n",
    "\n",
    "## set test loss to NaN\n",
    "test['loss'] = np.nan\n",
    "\n",
    "## response and IDs\n",
    "y = np.log(train['loss'].values+200)\n",
    "id_train = train['id'].values\n",
    "id_test = test['id'].values\n",
    "\n",
    "## stack train test\n",
    "ntrain = train.shape[0]\n",
    "tr_te = pd.concat((train, test), axis = 0)\n",
    "\n",
    "## Preprocessing and transforming to sparse data\n",
    "sparse_data = []\n",
    "\n",
    "f_cat = [f for f in tr_te.columns if 'cat' in f]\n",
    "for f in f_cat:\n",
    "    dummy = pd.get_dummies(tr_te[f].astype('category'))\n",
    "    tmp = csr_matrix(dummy)\n",
    "    sparse_data.append(tmp)\n",
    "\n",
    "f_num = [f for f in tr_te.columns if 'cont' in f]\n",
    "scaler = StandardScaler()\n",
    "tmp = csr_matrix(scaler.fit_transform(tr_te[f_num]))\n",
    "sparse_data.append(tmp)\n",
    "\n",
    "del(tr_te, train, test)\n",
    "\n",
    "## sparse train and test data\n",
    "xtr_te = hstack(sparse_data, format = 'csr')\n",
    "xtrain = xtr_te[:ntrain, :]\n",
    "xtest = xtr_te[ntrain:, :]\n",
    "\n",
    "print('Dim train', xtrain.shape)\n",
    "print('Dim test', xtest.shape)\n",
    "\n",
    "del(xtr_te, sparse_data, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36856cf8-a144-41b9-b370-61ff2e36d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f054bd2-0ec3-4b21-af8c-c35ab80f018c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.56987608, 7.84829365, 7.41602364, ..., 7.33236921, 9.17228019,\n",
       "       6.37051723])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "037bf2c6-0a5a-4fbd-87e3-d3d8388c44f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<188318x1190 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 24481340 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9047024c-9168-419c-8a1f-c8be7481e920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (1190,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and targets\n",
    "X = xtrain\n",
    "Y = y\n",
    "\n",
    "# Set the input shape\n",
    "input_shape = (xtrain.shape[1],)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f2eecd1-18fb-4126-82bd-83cac46378c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  1.        , ..., -0.95914517,\n",
       "        -0.61232072, -1.26329393],\n",
       "       [ 1.        ,  0.        ,  1.        , ...,  0.39395194,\n",
       "        -0.71240011, -1.1963163 ],\n",
       "       [ 1.        ,  0.        ,  1.        , ...,  0.91652738,\n",
       "         0.94750019, -0.90385702],\n",
       "       ...,\n",
       "       [ 0.        ,  1.        ,  1.        , ..., -0.83567771,\n",
       "        -0.01839175,  1.55127219],\n",
       "       [ 1.        ,  0.        ,  0.        , ..., -0.23903515,\n",
       "        -0.80958157, -0.56602101],\n",
       "       [ 0.        ,  1.        ,  1.        , ...,  0.39395194,\n",
       "         1.53407398, -0.95125139]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6dfabe5-e0f5-4815-9ab9-2364b9e40d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6447 - mae: 1.6447 - val_loss: 0.4246 - val_mae: 0.4246\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4045 - mae: 0.4045 - val_loss: 0.3957 - val_mae: 0.3957\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3892 - mae: 0.3892 - val_loss: 0.3896 - val_mae: 0.3896\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3846 - mae: 0.3846 - val_loss: 0.3862 - val_mae: 0.3862\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3826 - mae: 0.3826 - val_loss: 0.3844 - val_mae: 0.3844\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3815 - mae: 0.3815 - val_loss: 0.3839 - val_mae: 0.3839\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3809 - mae: 0.3809 - val_loss: 0.3842 - val_mae: 0.3842\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3805 - mae: 0.3805 - val_loss: 0.3831 - val_mae: 0.3831\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3804 - mae: 0.3804 - val_loss: 0.3830 - val_mae: 0.3830\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3802 - mae: 0.3802 - val_loss: 0.3846 - val_mae: 0.3846\n",
      "Epoch 11/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3800 - mae: 0.3800 - val_loss: 0.3836 - val_mae: 0.3836\n",
      "Epoch 12/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3801 - mae: 0.3801 - val_loss: 0.3833 - val_mae: 0.3833\n",
      "Epoch 13/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3796 - mae: 0.3796 - val_loss: 0.3831 - val_mae: 0.3831\n",
      "Epoch 14/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3800 - mae: 0.3800 - val_loss: 0.3846 - val_mae: 0.3846\n",
      "Epoch 15/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3800 - mae: 0.3800 - val_loss: 0.3844 - val_mae: 0.3844\n",
      "Epoch 16/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3792 - mae: 0.3792 - val_loss: 0.3848 - val_mae: 0.3848\n",
      "Epoch 17/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3798 - mae: 0.3798 - val_loss: 0.3834 - val_mae: 0.3834\n",
      "Epoch 18/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3797 - mae: 0.3797 - val_loss: 0.3835 - val_mae: 0.3835\n",
      "Epoch 19/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3792 - mae: 0.3792 - val_loss: 0.3843 - val_mae: 0.3843\n",
      "Epoch 20/20\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3791 - mae: 0.3791 - val_loss: 0.3840 - val_mae: 0.3840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20e41ee070>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "model.fit(X.toarray(), Y, epochs=20, batch_size=1024, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "071c4965-402f-49a8-9473-c6b656afe959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1296.1677],\n",
       "       [ 1648.4943],\n",
       "       [11054.149 ],\n",
       "       ...,\n",
       "       [ 2436.859 ],\n",
       "       [  904.2169],\n",
       "       [ 3309.8083]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.exp(model.predict(xtest))-200\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14a51b18-a357-473c-b588-19ecdb5b93bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1296.167725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1648.494263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>11054.149414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>5829.130859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>771.655334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          loss\n",
       "0   4   1296.167725\n",
       "1   6   1648.494263\n",
       "2   9  11054.149414\n",
       "3  12   5829.130859\n",
       "4  15    771.655334"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['loss'] = preds\n",
    "submission.to_csv('../submissions/sub_simple_mlp_0.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a6875dc5-6787-4f3d-93c0-b194c87fa1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## neural net\n",
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(400, input_dim = xtrain.shape[1], kernel_initializer = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "        \n",
    "    model.add(Dense(200, kernel_initializer = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(50, kernel_initializer = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer = 'he_normal'))\n",
    "    model.compile(loss = 'mae', optimizer = 'adadelta')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "673cd1c7-56c5-4ebf-bf9a-e63666065216",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09a62f30-1ca2-4ec8-8445-b2cf301a09f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.8005 - val_loss: 8.2878\n",
      "Epoch 2/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.7985 - val_loss: 8.3257\n",
      "Epoch 3/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7923 - val_loss: 8.1962\n",
      "Epoch 4/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7952 - val_loss: 8.0987\n",
      "Epoch 5/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.7886 - val_loss: 8.0501\n",
      "Epoch 6/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.7809 - val_loss: 8.0358\n",
      "Epoch 7/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7810 - val_loss: 8.0325\n",
      "Epoch 8/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7800 - val_loss: 8.0283\n",
      "Epoch 9/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7713 - val_loss: 8.0263\n",
      "Epoch 10/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7709 - val_loss: 8.0255\n",
      "Epoch 11/600\n",
      "148/148 [==============================] - ETA: 0s - loss: 7.765 - 1s 4ms/step - loss: 7.7657 - val_loss: 8.0160\n",
      "Epoch 12/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.7614 - val_loss: 8.0110\n",
      "Epoch 13/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.7541 - val_loss: 8.0060\n",
      "Epoch 14/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7456 - val_loss: 8.0036\n",
      "Epoch 15/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7446 - val_loss: 7.9946\n",
      "Epoch 16/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.7388 - val_loss: 7.9921\n",
      "Epoch 17/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7300 - val_loss: 7.9895\n",
      "Epoch 18/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.7270 - val_loss: 7.9854\n",
      "Epoch 19/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.7248 - val_loss: 7.9754\n",
      "Epoch 20/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.7188 - val_loss: 7.9707\n",
      "Epoch 21/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.7130 - val_loss: 7.9649\n",
      "Epoch 22/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.7061 - val_loss: 7.9605\n",
      "Epoch 23/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.7017 - val_loss: 7.9529\n",
      "Epoch 24/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.6914 - val_loss: 7.9462\n",
      "Epoch 25/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.6876 - val_loss: 7.9410\n",
      "Epoch 26/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.6790 - val_loss: 7.9338\n",
      "Epoch 27/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.6730 - val_loss: 7.9224\n",
      "Epoch 28/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.6650 - val_loss: 7.9163\n",
      "Epoch 29/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.6579 - val_loss: 7.9109\n",
      "Epoch 30/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.6500 - val_loss: 7.9026\n",
      "Epoch 31/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.6429 - val_loss: 7.8987\n",
      "Epoch 32/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.6367 - val_loss: 7.8834\n",
      "Epoch 33/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.6302 - val_loss: 7.8800\n",
      "Epoch 34/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.6176 - val_loss: 7.8775\n",
      "Epoch 35/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.6156 - val_loss: 7.8628\n",
      "Epoch 36/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.6079 - val_loss: 7.8504\n",
      "Epoch 37/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.5917 - val_loss: 7.8461\n",
      "Epoch 38/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.5855 - val_loss: 7.8423\n",
      "Epoch 39/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.5795 - val_loss: 7.8369\n",
      "Epoch 40/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.5682 - val_loss: 7.8248\n",
      "Epoch 41/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.5633 - val_loss: 7.8114\n",
      "Epoch 42/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.5510 - val_loss: 7.8000\n",
      "Epoch 43/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.5435 - val_loss: 7.7919\n",
      "Epoch 44/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.5364 - val_loss: 7.7833\n",
      "Epoch 45/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.5247 - val_loss: 7.7744\n",
      "Epoch 46/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.5173 - val_loss: 7.7662\n",
      "Epoch 47/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.5084 - val_loss: 7.7579\n",
      "Epoch 48/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.4986 - val_loss: 7.7520\n",
      "Epoch 49/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.4891 - val_loss: 7.7406\n",
      "Epoch 50/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.4848 - val_loss: 7.7297\n",
      "Epoch 51/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.4709 - val_loss: 7.7195\n",
      "Epoch 52/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.4617 - val_loss: 7.7110\n",
      "Epoch 53/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.4495 - val_loss: 7.7046\n",
      "Epoch 54/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.4394 - val_loss: 7.6903\n",
      "Epoch 55/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.4294 - val_loss: 7.6811\n",
      "Epoch 56/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.4203 - val_loss: 7.6748\n",
      "Epoch 57/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.4084 - val_loss: 7.6599\n",
      "Epoch 58/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.4008 - val_loss: 7.6453\n",
      "Epoch 59/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.3815 - val_loss: 7.6408\n",
      "Epoch 60/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.3743 - val_loss: 7.6325\n",
      "Epoch 61/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.3647 - val_loss: 7.6199\n",
      "Epoch 62/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.3515 - val_loss: 7.6056\n",
      "Epoch 63/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.3425 - val_loss: 7.5893\n",
      "Epoch 64/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.3286 - val_loss: 7.5810\n",
      "Epoch 65/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.3206 - val_loss: 7.5670\n",
      "Epoch 66/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.3085 - val_loss: 7.5500\n",
      "Epoch 67/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7.2957 - val_loss: 7.5454\n",
      "Epoch 68/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.2837 - val_loss: 7.5359\n",
      "Epoch 69/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.2730 - val_loss: 7.5175\n",
      "Epoch 70/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.2558 - val_loss: 7.5063\n",
      "Epoch 71/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.2481 - val_loss: 7.4998\n",
      "Epoch 72/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.2346 - val_loss: 7.4779\n",
      "Epoch 73/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.2221 - val_loss: 7.4672\n",
      "Epoch 74/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.2056 - val_loss: 7.4544\n",
      "Epoch 75/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7.1931 - val_loss: 7.4454\n",
      "Epoch 76/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.1844 - val_loss: 7.4339\n",
      "Epoch 77/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.1657 - val_loss: 7.4227\n",
      "Epoch 78/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.1533 - val_loss: 7.4068\n",
      "Epoch 79/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.1377 - val_loss: 7.3921\n",
      "Epoch 80/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.1260 - val_loss: 7.3749\n",
      "Epoch 81/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.1105 - val_loss: 7.3604\n",
      "Epoch 82/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.0979 - val_loss: 7.3465\n",
      "Epoch 83/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.0829 - val_loss: 7.3274\n",
      "Epoch 84/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.0639 - val_loss: 7.3191\n",
      "Epoch 85/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.0502 - val_loss: 7.3017\n",
      "Epoch 86/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.0359 - val_loss: 7.2855\n",
      "Epoch 87/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.0192 - val_loss: 7.2757\n",
      "Epoch 88/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 7.0033 - val_loss: 7.2562\n",
      "Epoch 89/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.9916 - val_loss: 7.2335\n",
      "Epoch 90/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.9742 - val_loss: 7.2133\n",
      "Epoch 91/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.9526 - val_loss: 7.2059\n",
      "Epoch 92/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.9383 - val_loss: 7.1921\n",
      "Epoch 93/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.9228 - val_loss: 7.1710\n",
      "Epoch 94/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.9048 - val_loss: 7.1511\n",
      "Epoch 95/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.8899 - val_loss: 7.1334\n",
      "Epoch 96/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.8686 - val_loss: 7.1196\n",
      "Epoch 97/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.8517 - val_loss: 7.1021\n",
      "Epoch 98/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.8328 - val_loss: 7.0850\n",
      "Epoch 99/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.8156 - val_loss: 7.0594\n",
      "Epoch 100/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.8037 - val_loss: 7.0440\n",
      "Epoch 101/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.7808 - val_loss: 7.0238\n",
      "Epoch 102/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.7600 - val_loss: 7.0030\n",
      "Epoch 103/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.7407 - val_loss: 6.9864\n",
      "Epoch 104/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.7237 - val_loss: 6.9615\n",
      "Epoch 105/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.7009 - val_loss: 6.9342\n",
      "Epoch 106/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.6782 - val_loss: 6.9268\n",
      "Epoch 107/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 6.6573 - val_loss: 6.9008\n",
      "Epoch 108/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.6394 - val_loss: 6.8818\n",
      "Epoch 109/600\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 6.6174 - val_loss: 6.8597\n",
      "Epoch 110/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.5940 - val_loss: 6.8377\n",
      "Epoch 111/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.5733 - val_loss: 6.8197\n",
      "Epoch 112/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.5533 - val_loss: 6.7903\n",
      "Epoch 113/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.5333 - val_loss: 6.7665\n",
      "Epoch 114/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.5054 - val_loss: 6.7449\n",
      "Epoch 115/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.4825 - val_loss: 6.7152\n",
      "Epoch 116/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.4616 - val_loss: 6.6912\n",
      "Epoch 117/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.4365 - val_loss: 6.6629\n",
      "Epoch 118/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.4114 - val_loss: 6.6414\n",
      "Epoch 119/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.3855 - val_loss: 6.6101\n",
      "Epoch 120/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.3608 - val_loss: 6.5943\n",
      "Epoch 121/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.3357 - val_loss: 6.5632\n",
      "Epoch 122/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.3090 - val_loss: 6.5309\n",
      "Epoch 123/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.2863 - val_loss: 6.5061\n",
      "Epoch 124/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.2541 - val_loss: 6.4770\n",
      "Epoch 125/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.2291 - val_loss: 6.4515\n",
      "Epoch 126/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.2020 - val_loss: 6.4202\n",
      "Epoch 127/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.1681 - val_loss: 6.3902\n",
      "Epoch 128/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.1410 - val_loss: 6.3633\n",
      "Epoch 129/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.1077 - val_loss: 6.3213\n",
      "Epoch 130/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.0811 - val_loss: 6.2932\n",
      "Epoch 131/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.0493 - val_loss: 6.2671\n",
      "Epoch 132/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 6.0191 - val_loss: 6.2339\n",
      "Epoch 133/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.9896 - val_loss: 6.2016\n",
      "Epoch 134/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.9567 - val_loss: 6.1617\n",
      "Epoch 135/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.9186 - val_loss: 6.1257\n",
      "Epoch 136/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5.8888 - val_loss: 6.0866\n",
      "Epoch 137/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.8479 - val_loss: 6.0620\n",
      "Epoch 138/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.8210 - val_loss: 6.0255\n",
      "Epoch 139/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.7856 - val_loss: 5.9822\n",
      "Epoch 140/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.7494 - val_loss: 5.9419\n",
      "Epoch 141/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5.7081 - val_loss: 5.8983\n",
      "Epoch 142/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5.6744 - val_loss: 5.8663\n",
      "Epoch 143/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5.6330 - val_loss: 5.8231\n",
      "Epoch 144/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.5990 - val_loss: 5.7726\n",
      "Epoch 145/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.5567 - val_loss: 5.7405\n",
      "Epoch 146/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.5129 - val_loss: 5.6900\n",
      "Epoch 147/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.4769 - val_loss: 5.6444\n",
      "Epoch 148/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.4329 - val_loss: 5.5991\n",
      "Epoch 149/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.3907 - val_loss: 5.5488\n",
      "Epoch 150/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.3418 - val_loss: 5.5066\n",
      "Epoch 151/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.3006 - val_loss: 5.4534\n",
      "Epoch 152/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.2556 - val_loss: 5.4061\n",
      "Epoch 153/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5.2018 - val_loss: 5.3591\n",
      "Epoch 154/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.1596 - val_loss: 5.3078\n",
      "Epoch 155/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.1089 - val_loss: 5.2500\n",
      "Epoch 156/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.0633 - val_loss: 5.1812\n",
      "Epoch 157/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 5.0113 - val_loss: 5.1258\n",
      "Epoch 158/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.9598 - val_loss: 5.0734\n",
      "Epoch 159/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.9055 - val_loss: 5.0280\n",
      "Epoch 160/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.8542 - val_loss: 4.9635\n",
      "Epoch 161/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.7940 - val_loss: 4.8976\n",
      "Epoch 162/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.7426 - val_loss: 4.8337\n",
      "Epoch 163/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.6850 - val_loss: 4.7728\n",
      "Epoch 164/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.6238 - val_loss: 4.7004\n",
      "Epoch 165/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.5638 - val_loss: 4.6341\n",
      "Epoch 166/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.4977 - val_loss: 4.5640\n",
      "Epoch 167/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.4376 - val_loss: 4.4901\n",
      "Epoch 168/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.3818 - val_loss: 4.4258\n",
      "Epoch 169/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.3125 - val_loss: 4.3553\n",
      "Epoch 170/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.2525 - val_loss: 4.2742\n",
      "Epoch 171/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.1817 - val_loss: 4.1977\n",
      "Epoch 172/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.1172 - val_loss: 4.1263\n",
      "Epoch 173/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 4.0423 - val_loss: 4.0439\n",
      "Epoch 174/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.9784 - val_loss: 3.9649\n",
      "Epoch 175/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.9109 - val_loss: 3.8829\n",
      "Epoch 176/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.8393 - val_loss: 3.8020\n",
      "Epoch 177/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.7664 - val_loss: 3.7161\n",
      "Epoch 178/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.7007 - val_loss: 3.6265\n",
      "Epoch 179/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.6247 - val_loss: 3.5429\n",
      "Epoch 180/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.5495 - val_loss: 3.4601\n",
      "Epoch 181/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.4780 - val_loss: 3.3731\n",
      "Epoch 182/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.4052 - val_loss: 3.2873\n",
      "Epoch 183/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.3243 - val_loss: 3.1887\n",
      "Epoch 184/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.2598 - val_loss: 3.0995\n",
      "Epoch 185/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.1804 - val_loss: 3.0155\n",
      "Epoch 186/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 3.1124 - val_loss: 2.9224\n",
      "Epoch 187/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.0366 - val_loss: 2.8248\n",
      "Epoch 188/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.9637 - val_loss: 2.7374\n",
      "Epoch 189/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.8987 - val_loss: 2.6389\n",
      "Epoch 190/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.8310 - val_loss: 2.5578\n",
      "Epoch 191/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.7701 - val_loss: 2.4667\n",
      "Epoch 192/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.6991 - val_loss: 2.3783\n",
      "Epoch 193/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.6319 - val_loss: 2.2946\n",
      "Epoch 194/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.5741 - val_loss: 2.2090\n",
      "Epoch 195/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.5212 - val_loss: 2.1287\n",
      "Epoch 196/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.4587 - val_loss: 2.0502\n",
      "Epoch 197/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.4077 - val_loss: 1.9689\n",
      "Epoch 198/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.3503 - val_loss: 1.8935\n",
      "Epoch 199/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.2962 - val_loss: 1.8248\n",
      "Epoch 200/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.2575 - val_loss: 1.7550\n",
      "Epoch 201/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.2170 - val_loss: 1.6891\n",
      "Epoch 202/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.1662 - val_loss: 1.6284\n",
      "Epoch 203/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.1297 - val_loss: 1.5655\n",
      "Epoch 204/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.0957 - val_loss: 1.5104\n",
      "Epoch 205/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.0571 - val_loss: 1.4598\n",
      "Epoch 206/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.0324 - val_loss: 1.4106\n",
      "Epoch 207/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.0034 - val_loss: 1.3663\n",
      "Epoch 208/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.9717 - val_loss: 1.3205\n",
      "Epoch 209/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.9395 - val_loss: 1.2801\n",
      "Epoch 210/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.9235 - val_loss: 1.2438\n",
      "Epoch 211/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.9045 - val_loss: 1.2105\n",
      "Epoch 212/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.8818 - val_loss: 1.1795\n",
      "Epoch 213/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.8595 - val_loss: 1.1536\n",
      "Epoch 214/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.8441 - val_loss: 1.1263\n",
      "Epoch 215/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.8280 - val_loss: 1.0992\n",
      "Epoch 216/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.8116 - val_loss: 1.0778\n",
      "Epoch 217/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7974 - val_loss: 1.0586\n",
      "Epoch 218/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7897 - val_loss: 1.0384\n",
      "Epoch 219/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7743 - val_loss: 1.0209\n",
      "Epoch 220/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7573 - val_loss: 1.0054\n",
      "Epoch 221/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7512 - val_loss: 0.9910\n",
      "Epoch 222/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7481 - val_loss: 0.9772\n",
      "Epoch 223/600\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.7366 - val_loss: 0.9624\n",
      "Epoch 224/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7221 - val_loss: 0.9493\n",
      "Epoch 225/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7217 - val_loss: 0.9398\n",
      "Epoch 226/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7115 - val_loss: 0.9297\n",
      "Epoch 227/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.7045 - val_loss: 0.9195\n",
      "Epoch 228/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6919 - val_loss: 0.9118\n",
      "Epoch 229/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6852 - val_loss: 0.9043\n",
      "Epoch 230/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6813 - val_loss: 0.8951\n",
      "Epoch 231/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6745 - val_loss: 0.8874\n",
      "Epoch 232/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6653 - val_loss: 0.8784\n",
      "Epoch 233/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6642 - val_loss: 0.8741\n",
      "Epoch 234/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6476 - val_loss: 0.8658\n",
      "Epoch 235/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6483 - val_loss: 0.8616\n",
      "Epoch 236/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6465 - val_loss: 0.8549\n",
      "Epoch 237/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6408 - val_loss: 0.8507\n",
      "Epoch 238/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6348 - val_loss: 0.8440\n",
      "Epoch 239/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6294 - val_loss: 0.8389\n",
      "Epoch 240/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6259 - val_loss: 0.8352\n",
      "Epoch 241/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6185 - val_loss: 0.8312\n",
      "Epoch 242/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6173 - val_loss: 0.8254\n",
      "Epoch 243/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6060 - val_loss: 0.8207\n",
      "Epoch 244/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6027 - val_loss: 0.8172\n",
      "Epoch 245/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.6021 - val_loss: 0.8129\n",
      "Epoch 246/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5913 - val_loss: 0.8102\n",
      "Epoch 247/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5862 - val_loss: 0.8065\n",
      "Epoch 248/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5935 - val_loss: 0.8027\n",
      "Epoch 249/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5816 - val_loss: 0.7989\n",
      "Epoch 250/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5795 - val_loss: 0.7951\n",
      "Epoch 251/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5759 - val_loss: 0.7934\n",
      "Epoch 252/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5705 - val_loss: 0.7908\n",
      "Epoch 253/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5745 - val_loss: 0.7878\n",
      "Epoch 254/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5637 - val_loss: 0.7832\n",
      "Epoch 255/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5597 - val_loss: 0.7803\n",
      "Epoch 256/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5548 - val_loss: 0.7788\n",
      "Epoch 257/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5569 - val_loss: 0.7757\n",
      "Epoch 258/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5556 - val_loss: 0.7722\n",
      "Epoch 259/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5435 - val_loss: 0.7706\n",
      "Epoch 260/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5447 - val_loss: 0.7686\n",
      "Epoch 261/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5394 - val_loss: 0.7638\n",
      "Epoch 262/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5337 - val_loss: 0.7611\n",
      "Epoch 263/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5304 - val_loss: 0.7590\n",
      "Epoch 264/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5305 - val_loss: 0.7584\n",
      "Epoch 265/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5347 - val_loss: 0.7540\n",
      "Epoch 266/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5283 - val_loss: 0.7521\n",
      "Epoch 267/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5175 - val_loss: 0.7503\n",
      "Epoch 268/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5166 - val_loss: 0.7474\n",
      "Epoch 269/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5147 - val_loss: 0.7454\n",
      "Epoch 270/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5105 - val_loss: 0.7423\n",
      "Epoch 271/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5047 - val_loss: 0.7401\n",
      "Epoch 272/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5074 - val_loss: 0.7387\n",
      "Epoch 273/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.5028 - val_loss: 0.7369\n",
      "Epoch 274/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4994 - val_loss: 0.7343\n",
      "Epoch 275/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4940 - val_loss: 0.7330\n",
      "Epoch 276/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4903 - val_loss: 0.7304\n",
      "Epoch 277/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4886 - val_loss: 0.7287\n",
      "Epoch 278/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4840 - val_loss: 0.7272\n",
      "Epoch 279/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4861 - val_loss: 0.7249\n",
      "Epoch 280/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4820 - val_loss: 0.7230\n",
      "Epoch 281/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4775 - val_loss: 0.7202\n",
      "Epoch 282/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4696 - val_loss: 0.7198\n",
      "Epoch 283/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4721 - val_loss: 0.7174\n",
      "Epoch 284/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4691 - val_loss: 0.7159\n",
      "Epoch 285/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4699 - val_loss: 0.7137\n",
      "Epoch 286/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4652 - val_loss: 0.7124\n",
      "Epoch 287/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4635 - val_loss: 0.7107\n",
      "Epoch 288/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4604 - val_loss: 0.7084\n",
      "Epoch 289/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4608 - val_loss: 0.7067\n",
      "Epoch 290/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4574 - val_loss: 0.7058\n",
      "Epoch 291/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4572 - val_loss: 0.7038\n",
      "Epoch 292/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4494 - val_loss: 0.7027\n",
      "Epoch 293/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4501 - val_loss: 0.7003\n",
      "Epoch 294/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4456 - val_loss: 0.6974\n",
      "Epoch 295/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4451 - val_loss: 0.6973\n",
      "Epoch 296/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4412 - val_loss: 0.6963\n",
      "Epoch 297/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4342 - val_loss: 0.6949\n",
      "Epoch 298/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4357 - val_loss: 0.6931\n",
      "Epoch 299/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4298 - val_loss: 0.6926\n",
      "Epoch 300/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4270 - val_loss: 0.6894\n",
      "Epoch 301/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4304 - val_loss: 0.6878\n",
      "Epoch 302/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4253 - val_loss: 0.6864\n",
      "Epoch 303/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4250 - val_loss: 0.6851\n",
      "Epoch 304/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4195 - val_loss: 0.6838\n",
      "Epoch 305/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4179 - val_loss: 0.6833\n",
      "Epoch 306/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4206 - val_loss: 0.6814\n",
      "Epoch 307/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4170 - val_loss: 0.6797\n",
      "Epoch 308/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4132 - val_loss: 0.6783\n",
      "Epoch 309/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4124 - val_loss: 0.6774\n",
      "Epoch 310/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4079 - val_loss: 0.6767\n",
      "Epoch 311/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4102 - val_loss: 0.6741\n",
      "Epoch 312/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4025 - val_loss: 0.6741\n",
      "Epoch 313/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4001 - val_loss: 0.6723\n",
      "Epoch 314/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.4052 - val_loss: 0.6704\n",
      "Epoch 315/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3980 - val_loss: 0.6702\n",
      "Epoch 316/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3948 - val_loss: 0.6693\n",
      "Epoch 317/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3912 - val_loss: 0.6666\n",
      "Epoch 318/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3941 - val_loss: 0.6653\n",
      "Epoch 319/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3847 - val_loss: 0.6639\n",
      "Epoch 320/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3868 - val_loss: 0.6639\n",
      "Epoch 321/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3903 - val_loss: 0.6624\n",
      "Epoch 322/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3779 - val_loss: 0.6619\n",
      "Epoch 323/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3804 - val_loss: 0.6610\n",
      "Epoch 324/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3823 - val_loss: 0.6593\n",
      "Epoch 325/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3767 - val_loss: 0.6584\n",
      "Epoch 326/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3754 - val_loss: 0.6567\n",
      "Epoch 327/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3714 - val_loss: 0.6560\n",
      "Epoch 328/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3728 - val_loss: 0.6536\n",
      "Epoch 329/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3687 - val_loss: 0.6521\n",
      "Epoch 330/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3720 - val_loss: 0.6509\n",
      "Epoch 331/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3617 - val_loss: 0.6506\n",
      "Epoch 332/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3604 - val_loss: 0.6495\n",
      "Epoch 333/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3586 - val_loss: 0.6483\n",
      "Epoch 334/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3615 - val_loss: 0.6464\n",
      "Epoch 335/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3583 - val_loss: 0.6457\n",
      "Epoch 336/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3556 - val_loss: 0.6436\n",
      "Epoch 337/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3542 - val_loss: 0.6439\n",
      "Epoch 338/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3507 - val_loss: 0.6419\n",
      "Epoch 339/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3482 - val_loss: 0.6410\n",
      "Epoch 340/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3524 - val_loss: 0.6417\n",
      "Epoch 341/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3530 - val_loss: 0.6403\n",
      "Epoch 342/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3463 - val_loss: 0.6379\n",
      "Epoch 343/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3469 - val_loss: 0.6379\n",
      "Epoch 344/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3406 - val_loss: 0.6373\n",
      "Epoch 345/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3459 - val_loss: 0.6355\n",
      "Epoch 346/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3382 - val_loss: 0.6343\n",
      "Epoch 347/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3406 - val_loss: 0.6350\n",
      "Epoch 348/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3341 - val_loss: 0.6328\n",
      "Epoch 349/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3301 - val_loss: 0.6325\n",
      "Epoch 350/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3321 - val_loss: 0.6309\n",
      "Epoch 351/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3329 - val_loss: 0.6306\n",
      "Epoch 352/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3300 - val_loss: 0.6284\n",
      "Epoch 353/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3251 - val_loss: 0.6277\n",
      "Epoch 354/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3282 - val_loss: 0.6271\n",
      "Epoch 355/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3234 - val_loss: 0.6272\n",
      "Epoch 356/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3252 - val_loss: 0.6261\n",
      "Epoch 357/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3205 - val_loss: 0.6254\n",
      "Epoch 358/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3199 - val_loss: 0.6239\n",
      "Epoch 359/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3129 - val_loss: 0.6234\n",
      "Epoch 360/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3166 - val_loss: 0.6223\n",
      "Epoch 361/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3141 - val_loss: 0.6206\n",
      "Epoch 362/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3136 - val_loss: 0.6195\n",
      "Epoch 363/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3073 - val_loss: 0.6189\n",
      "Epoch 364/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3082 - val_loss: 0.6177\n",
      "Epoch 365/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3044 - val_loss: 0.6176\n",
      "Epoch 366/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3078 - val_loss: 0.6168\n",
      "Epoch 367/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3068 - val_loss: 0.6147\n",
      "Epoch 368/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3082 - val_loss: 0.6141\n",
      "Epoch 369/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3086 - val_loss: 0.6133\n",
      "Epoch 370/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.3030 - val_loss: 0.6125\n",
      "Epoch 371/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2978 - val_loss: 0.6126\n",
      "Epoch 372/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2940 - val_loss: 0.6128\n",
      "Epoch 373/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2935 - val_loss: 0.6114\n",
      "Epoch 374/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2963 - val_loss: 0.6102\n",
      "Epoch 375/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2917 - val_loss: 0.6089\n",
      "Epoch 376/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2927 - val_loss: 0.6080\n",
      "Epoch 377/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2902 - val_loss: 0.6072\n",
      "Epoch 378/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2870 - val_loss: 0.6069\n",
      "Epoch 379/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2847 - val_loss: 0.6056\n",
      "Epoch 380/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2843 - val_loss: 0.6032\n",
      "Epoch 381/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2838 - val_loss: 0.6039\n",
      "Epoch 382/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2829 - val_loss: 0.6027\n",
      "Epoch 383/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2789 - val_loss: 0.6023\n",
      "Epoch 384/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2778 - val_loss: 0.6020\n",
      "Epoch 385/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2760 - val_loss: 0.6001\n",
      "Epoch 386/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2793 - val_loss: 0.5986\n",
      "Epoch 387/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2796 - val_loss: 0.5983\n",
      "Epoch 388/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2758 - val_loss: 0.5982\n",
      "Epoch 389/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2737 - val_loss: 0.5969\n",
      "Epoch 390/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2686 - val_loss: 0.5962\n",
      "Epoch 391/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2707 - val_loss: 0.5953\n",
      "Epoch 392/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2713 - val_loss: 0.5943\n",
      "Epoch 393/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2676 - val_loss: 0.5938\n",
      "Epoch 394/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2608 - val_loss: 0.5937\n",
      "Epoch 395/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2662 - val_loss: 0.5924\n",
      "Epoch 396/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2647 - val_loss: 0.5910\n",
      "Epoch 397/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2629 - val_loss: 0.5912\n",
      "Epoch 398/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2624 - val_loss: 0.5908\n",
      "Epoch 399/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2592 - val_loss: 0.5897\n",
      "Epoch 400/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2652 - val_loss: 0.5894\n",
      "Epoch 401/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2518 - val_loss: 0.5885\n",
      "Epoch 402/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2522 - val_loss: 0.5878\n",
      "Epoch 403/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2505 - val_loss: 0.5873\n",
      "Epoch 404/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2552 - val_loss: 0.5863\n",
      "Epoch 405/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2555 - val_loss: 0.5854\n",
      "Epoch 406/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2496 - val_loss: 0.5846\n",
      "Epoch 407/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2469 - val_loss: 0.5834\n",
      "Epoch 408/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2484 - val_loss: 0.5833\n",
      "Epoch 409/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2469 - val_loss: 0.5838\n",
      "Epoch 410/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2468 - val_loss: 0.5832\n",
      "Epoch 411/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2450 - val_loss: 0.5809\n",
      "Epoch 412/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2409 - val_loss: 0.5802\n",
      "Epoch 413/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2459 - val_loss: 0.5801\n",
      "Epoch 414/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2357 - val_loss: 0.5786\n",
      "Epoch 415/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2389 - val_loss: 0.5780\n",
      "Epoch 416/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2345 - val_loss: 0.5779\n",
      "Epoch 417/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2374 - val_loss: 0.5771\n",
      "Epoch 418/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2305 - val_loss: 0.5761\n",
      "Epoch 419/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2315 - val_loss: 0.5750\n",
      "Epoch 420/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2325 - val_loss: 0.5748\n",
      "Epoch 421/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2319 - val_loss: 0.5745\n",
      "Epoch 422/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2281 - val_loss: 0.5743\n",
      "Epoch 423/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2267 - val_loss: 0.5737\n",
      "Epoch 424/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2291 - val_loss: 0.5720\n",
      "Epoch 425/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2276 - val_loss: 0.5719\n",
      "Epoch 426/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2260 - val_loss: 0.5704\n",
      "Epoch 427/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2250 - val_loss: 0.5697\n",
      "Epoch 428/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2192 - val_loss: 0.5689\n",
      "Epoch 429/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2198 - val_loss: 0.5686\n",
      "Epoch 430/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2217 - val_loss: 0.5677\n",
      "Epoch 431/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2135 - val_loss: 0.5679\n",
      "Epoch 432/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2200 - val_loss: 0.5681\n",
      "Epoch 433/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2117 - val_loss: 0.5675\n",
      "Epoch 434/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2166 - val_loss: 0.5659\n",
      "Epoch 435/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2169 - val_loss: 0.5658\n",
      "Epoch 436/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2113 - val_loss: 0.5651\n",
      "Epoch 437/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2123 - val_loss: 0.5644\n",
      "Epoch 438/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2129 - val_loss: 0.5634\n",
      "Epoch 439/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2154 - val_loss: 0.5635\n",
      "Epoch 440/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2074 - val_loss: 0.5621\n",
      "Epoch 441/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2058 - val_loss: 0.5622\n",
      "Epoch 442/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2035 - val_loss: 0.5613\n",
      "Epoch 443/600\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.204 - 1s 4ms/step - loss: 1.2048 - val_loss: 0.5608\n",
      "Epoch 444/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2016 - val_loss: 0.5598\n",
      "Epoch 445/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2031 - val_loss: 0.5595\n",
      "Epoch 446/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2065 - val_loss: 0.5590\n",
      "Epoch 447/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2043 - val_loss: 0.5587\n",
      "Epoch 448/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1966 - val_loss: 0.5579\n",
      "Epoch 449/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1963 - val_loss: 0.5575\n",
      "Epoch 450/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1899 - val_loss: 0.5560\n",
      "Epoch 451/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.2010 - val_loss: 0.5557\n",
      "Epoch 452/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1926 - val_loss: 0.5566\n",
      "Epoch 453/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1951 - val_loss: 0.5550\n",
      "Epoch 454/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1942 - val_loss: 0.5541\n",
      "Epoch 455/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1891 - val_loss: 0.5529\n",
      "Epoch 456/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1903 - val_loss: 0.5529\n",
      "Epoch 457/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1853 - val_loss: 0.5527\n",
      "Epoch 458/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1870 - val_loss: 0.5510\n",
      "Epoch 459/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1895 - val_loss: 0.5522\n",
      "Epoch 460/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1852 - val_loss: 0.5515\n",
      "Epoch 461/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1869 - val_loss: 0.5505\n",
      "Epoch 462/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1847 - val_loss: 0.5506\n",
      "Epoch 463/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1839 - val_loss: 0.5498\n",
      "Epoch 464/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1825 - val_loss: 0.5496\n",
      "Epoch 465/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1855 - val_loss: 0.5493\n",
      "Epoch 466/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1767 - val_loss: 0.5486\n",
      "Epoch 467/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1789 - val_loss: 0.5479\n",
      "Epoch 468/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1739 - val_loss: 0.5459\n",
      "Epoch 469/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1742 - val_loss: 0.5460\n",
      "Epoch 470/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1726 - val_loss: 0.5456\n",
      "Epoch 471/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1780 - val_loss: 0.5450\n",
      "Epoch 472/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1770 - val_loss: 0.5439\n",
      "Epoch 473/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1732 - val_loss: 0.5444\n",
      "Epoch 474/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1723 - val_loss: 0.5434\n",
      "Epoch 475/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1729 - val_loss: 0.5425\n",
      "Epoch 476/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1663 - val_loss: 0.5425\n",
      "Epoch 477/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1649 - val_loss: 0.5424\n",
      "Epoch 478/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1661 - val_loss: 0.5408\n",
      "Epoch 479/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1650 - val_loss: 0.5413\n",
      "Epoch 480/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1662 - val_loss: 0.5405\n",
      "Epoch 481/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1625 - val_loss: 0.5400\n",
      "Epoch 482/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1645 - val_loss: 0.5401\n",
      "Epoch 483/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1621 - val_loss: 0.5396\n",
      "Epoch 484/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1626 - val_loss: 0.5400\n",
      "Epoch 485/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1619 - val_loss: 0.5385\n",
      "Epoch 486/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1589 - val_loss: 0.5381\n",
      "Epoch 487/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1625 - val_loss: 0.5378\n",
      "Epoch 488/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1576 - val_loss: 0.5374\n",
      "Epoch 489/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1551 - val_loss: 0.5368\n",
      "Epoch 490/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1554 - val_loss: 0.5362\n",
      "Epoch 491/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1522 - val_loss: 0.5363\n",
      "Epoch 492/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1577 - val_loss: 0.5362\n",
      "Epoch 493/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1544 - val_loss: 0.5347\n",
      "Epoch 494/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1525 - val_loss: 0.5339\n",
      "Epoch 495/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1521 - val_loss: 0.5342\n",
      "Epoch 496/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1457 - val_loss: 0.5338\n",
      "Epoch 497/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1464 - val_loss: 0.5332\n",
      "Epoch 498/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1490 - val_loss: 0.5328\n",
      "Epoch 499/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1469 - val_loss: 0.5324\n",
      "Epoch 500/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1439 - val_loss: 0.5322\n",
      "Epoch 501/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1471 - val_loss: 0.5316\n",
      "Epoch 502/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1437 - val_loss: 0.5316\n",
      "Epoch 503/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1418 - val_loss: 0.5304\n",
      "Epoch 504/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1405 - val_loss: 0.5299\n",
      "Epoch 505/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1415 - val_loss: 0.5300\n",
      "Epoch 506/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1401 - val_loss: 0.5283\n",
      "Epoch 507/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1387 - val_loss: 0.5291\n",
      "Epoch 508/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1376 - val_loss: 0.5281\n",
      "Epoch 509/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1369 - val_loss: 0.5277\n",
      "Epoch 510/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1359 - val_loss: 0.5274\n",
      "Epoch 511/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1356 - val_loss: 0.5271\n",
      "Epoch 512/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1366 - val_loss: 0.5261\n",
      "Epoch 513/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1389 - val_loss: 0.5265\n",
      "Epoch 514/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1342 - val_loss: 0.5265\n",
      "Epoch 515/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1338 - val_loss: 0.5248\n",
      "Epoch 516/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1307 - val_loss: 0.5258\n",
      "Epoch 517/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1306 - val_loss: 0.5248\n",
      "Epoch 518/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1261 - val_loss: 0.5244\n",
      "Epoch 519/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1274 - val_loss: 0.5231\n",
      "Epoch 520/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1259 - val_loss: 0.5224\n",
      "Epoch 521/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1218 - val_loss: 0.5227\n",
      "Epoch 522/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1274 - val_loss: 0.5223\n",
      "Epoch 523/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1247 - val_loss: 0.5215\n",
      "Epoch 524/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1275 - val_loss: 0.5214\n",
      "Epoch 525/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1227 - val_loss: 0.5214\n",
      "Epoch 526/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1223 - val_loss: 0.5207\n",
      "Epoch 527/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1242 - val_loss: 0.5203\n",
      "Epoch 528/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1205 - val_loss: 0.5202\n",
      "Epoch 529/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1201 - val_loss: 0.5193\n",
      "Epoch 530/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1168 - val_loss: 0.5193\n",
      "Epoch 531/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1130 - val_loss: 0.5190\n",
      "Epoch 532/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1155 - val_loss: 0.5187\n",
      "Epoch 533/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1141 - val_loss: 0.5184\n",
      "Epoch 534/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1147 - val_loss: 0.5183\n",
      "Epoch 535/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1147 - val_loss: 0.5175\n",
      "Epoch 536/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1137 - val_loss: 0.5168\n",
      "Epoch 537/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1108 - val_loss: 0.5169\n",
      "Epoch 538/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1154 - val_loss: 0.5165\n",
      "Epoch 539/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1088 - val_loss: 0.5161\n",
      "Epoch 540/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1079 - val_loss: 0.5162\n",
      "Epoch 541/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1067 - val_loss: 0.5159\n",
      "Epoch 542/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1066 - val_loss: 0.5154\n",
      "Epoch 543/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1045 - val_loss: 0.5157\n",
      "Epoch 544/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1042 - val_loss: 0.5146\n",
      "Epoch 545/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1066 - val_loss: 0.5145\n",
      "Epoch 546/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1016 - val_loss: 0.5143\n",
      "Epoch 547/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1064 - val_loss: 0.5135\n",
      "Epoch 548/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1054 - val_loss: 0.5137\n",
      "Epoch 549/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0998 - val_loss: 0.5127\n",
      "Epoch 550/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1037 - val_loss: 0.5118\n",
      "Epoch 551/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0992 - val_loss: 0.5117\n",
      "Epoch 552/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.1027 - val_loss: 0.5111\n",
      "Epoch 553/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0979 - val_loss: 0.5111\n",
      "Epoch 554/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0965 - val_loss: 0.5109\n",
      "Epoch 555/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0974 - val_loss: 0.5105\n",
      "Epoch 556/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0974 - val_loss: 0.5100\n",
      "Epoch 557/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0977 - val_loss: 0.5097\n",
      "Epoch 558/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0930 - val_loss: 0.5093\n",
      "Epoch 559/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0909 - val_loss: 0.5091\n",
      "Epoch 560/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0934 - val_loss: 0.5087\n",
      "Epoch 561/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0899 - val_loss: 0.5085\n",
      "Epoch 562/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0917 - val_loss: 0.5078\n",
      "Epoch 563/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0935 - val_loss: 0.5074\n",
      "Epoch 564/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0868 - val_loss: 0.5076\n",
      "Epoch 565/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0899 - val_loss: 0.5074\n",
      "Epoch 566/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0871 - val_loss: 0.5067\n",
      "Epoch 567/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0892 - val_loss: 0.5059\n",
      "Epoch 568/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0876 - val_loss: 0.5057\n",
      "Epoch 569/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0858 - val_loss: 0.5049\n",
      "Epoch 570/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0834 - val_loss: 0.5046\n",
      "Epoch 571/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0792 - val_loss: 0.5042\n",
      "Epoch 572/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0808 - val_loss: 0.5048\n",
      "Epoch 573/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0792 - val_loss: 0.5043\n",
      "Epoch 574/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0838 - val_loss: 0.5035\n",
      "Epoch 575/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0828 - val_loss: 0.5033\n",
      "Epoch 576/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0809 - val_loss: 0.5031\n",
      "Epoch 577/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0811 - val_loss: 0.5020\n",
      "Epoch 578/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0802 - val_loss: 0.5021\n",
      "Epoch 579/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0814 - val_loss: 0.5019\n",
      "Epoch 580/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0752 - val_loss: 0.5007\n",
      "Epoch 581/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0753 - val_loss: 0.5004\n",
      "Epoch 582/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0781 - val_loss: 0.5006\n",
      "Epoch 583/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0800 - val_loss: 0.5006\n",
      "Epoch 584/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0709 - val_loss: 0.4999\n",
      "Epoch 585/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0731 - val_loss: 0.4990\n",
      "Epoch 586/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0753 - val_loss: 0.4988\n",
      "Epoch 587/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0731 - val_loss: 0.4989\n",
      "Epoch 588/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0726 - val_loss: 0.4984\n",
      "Epoch 589/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0702 - val_loss: 0.4983\n",
      "Epoch 590/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0718 - val_loss: 0.4984\n",
      "Epoch 591/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0710 - val_loss: 0.4981\n",
      "Epoch 592/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0689 - val_loss: 0.4975\n",
      "Epoch 593/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0682 - val_loss: 0.4971\n",
      "Epoch 594/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0670 - val_loss: 0.4967\n",
      "Epoch 595/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0652 - val_loss: 0.4965\n",
      "Epoch 596/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0676 - val_loss: 0.4963\n",
      "Epoch 597/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0673 - val_loss: 0.4953\n",
      "Epoch 598/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0660 - val_loss: 0.4955\n",
      "Epoch 599/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0651 - val_loss: 0.4957\n",
      "Epoch 600/600\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 1.0665 - val_loss: 0.4946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20c80a25b0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X.toarray(), Y, epochs=600, batch_size=1024, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c677ab8a-faa4-4504-a08c-3139bdd87a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 840.42236],\n",
       "       [1138.6089 ],\n",
       "       [2698.374  ],\n",
       "       ...,\n",
       "       [3150.0344 ],\n",
       "       [ 999.2999 ],\n",
       "       [2696.4177 ]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.exp(model.predict(xtest))-200\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "def99a6c-cade-4164-a46a-9be8efb03960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>840.422363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1138.608887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2698.374023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>4880.146484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>738.596924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         loss\n",
       "0   4   840.422363\n",
       "1   6  1138.608887\n",
       "2   9  2698.374023\n",
       "3  12  4880.146484\n",
       "4  15   738.596924"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['loss'] = preds\n",
    "submission.to_csv('../submissions/sub_cmplx_mlp_0.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7c70eab6-bdac-43fb-a578-4fce457eb28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.7430 - mae: 0.7430 - val_loss: 0.4228 - val_mae: 0.4228\n",
      "Epoch 2/20\n",
      "1507/1507 [==============================] - 8s 6ms/step - loss: 0.5887 - mae: 0.5887 - val_loss: 0.3990 - val_mae: 0.3990\n",
      "Epoch 3/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.5452 - mae: 0.5452 - val_loss: 0.3848 - val_mae: 0.3848\n",
      "Epoch 4/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.5183 - mae: 0.5183 - val_loss: 0.3968 - val_mae: 0.3968\n",
      "Epoch 5/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.4977 - mae: 0.4977 - val_loss: 0.3912 - val_mae: 0.3912\n",
      "Epoch 6/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.4814 - mae: 0.4814 - val_loss: 0.3830 - val_mae: 0.3830\n",
      "Epoch 7/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.4684 - mae: 0.4684 - val_loss: 0.3834 - val_mae: 0.3834\n",
      "Epoch 8/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.4555 - mae: 0.4555 - val_loss: 0.3787 - val_mae: 0.3787\n",
      "Epoch 9/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.4458 - mae: 0.4458 - val_loss: 0.3777 - val_mae: 0.3777\n",
      "Epoch 10/20\n",
      "1507/1507 [==============================] - 9s 6ms/step - loss: 0.4373 - mae: 0.4373 - val_loss: 0.3874 - val_mae: 0.3874\n",
      "Epoch 11/20\n",
      "1507/1507 [==============================] - 8s 6ms/step - loss: 0.4280 - mae: 0.4280 - val_loss: 0.3768 - val_mae: 0.3768\n",
      "Epoch 12/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.4223 - mae: 0.4223 - val_loss: 0.3861 - val_mae: 0.3861\n",
      "Epoch 13/20\n",
      "1507/1507 [==============================] - 8s 6ms/step - loss: 0.4154 - mae: 0.4154 - val_loss: 0.3766 - val_mae: 0.3766\n",
      "Epoch 14/20\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 0.4091 - mae: 0.4091 - val_loss: 0.3758 - val_mae: 0.3758\n",
      "Epoch 15/20\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 0.4049 - mae: 0.4049 - val_loss: 0.3817 - val_mae: 0.3817\n",
      "Epoch 16/20\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 0.4008 - mae: 0.4008 - val_loss: 0.3753 - val_mae: 0.3753\n",
      "Epoch 17/20\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 0.3970 - mae: 0.3970 - val_loss: 0.3758 - val_mae: 0.3758\n",
      "Epoch 18/20\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 0.3943 - mae: 0.3943 - val_loss: 0.3750 - val_mae: 0.3750\n",
      "Epoch 19/20\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 0.3903 - mae: 0.3903 - val_loss: 0.3741 - val_mae: 0.3741\n",
      "Epoch 20/20\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 0.3877 - mae: 0.3877 - val_loss: 0.3760 - val_mae: 0.3760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20b047a430>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "model.fit(X.toarray(), Y, epochs=20, batch_size=100, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7780c214-3107-47a0-bd1b-262985656035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1631.2096],\n",
       "       [1847.1476],\n",
       "       [9865.234 ],\n",
       "       ...,\n",
       "       [2451.0864],\n",
       "       [1141.5431],\n",
       "       [3928.2632]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.exp(model.predict(xtest))-200\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b59adc32-b450-412a-b33d-5d6c2724ba90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1631.209595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1847.147583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9865.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7891.284668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>862.370850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         loss\n",
       "0   4  1631.209595\n",
       "1   6  1847.147583\n",
       "2   9  9865.234375\n",
       "3  12  7891.284668\n",
       "4  15   862.370850"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['loss'] = preds\n",
    "submission.to_csv('../submissions/sub_cmplx_mlp_1.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6335c5e2-06cd-49a8-ba6c-948663c43d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 400)               476400    \n",
      "_________________________________________________________________\n",
      "p_re_lu_15 (PReLU)           (None, 400)               400       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "p_re_lu_16 (PReLU)           (None, 200)               200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "p_re_lu_17 (PReLU)           (None, 50)                50        \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 569,951\n",
      "Trainable params: 568,651\n",
      "Non-trainable params: 1,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dab482c7-958b-4ca4-be86-316083dc2d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3014/3014 [==============================] - 15s 5ms/step - loss: 0.3920 - mae: 0.3920 - val_loss: 0.3750 - val_mae: 0.3750\n",
      "Epoch 2/20\n",
      "3014/3014 [==============================] - 17s 6ms/step - loss: 0.3896 - mae: 0.3896 - val_loss: 0.3837 - val_mae: 0.3837\n",
      "Epoch 3/20\n",
      "3014/3014 [==============================] - 13s 4ms/step - loss: 0.3871 - mae: 0.3871 - val_loss: 0.3745 - val_mae: 0.3745\n",
      "Epoch 4/20\n",
      "3014/3014 [==============================] - 16s 5ms/step - loss: 0.3858 - mae: 0.3858 - val_loss: 0.3749 - val_mae: 0.3749\n",
      "Epoch 5/20\n",
      "3014/3014 [==============================] - 15s 5ms/step - loss: 0.3842 - mae: 0.3842 - val_loss: 0.3739 - val_mae: 0.3739\n",
      "Epoch 6/20\n",
      "3014/3014 [==============================] - 17s 6ms/step - loss: 0.3829 - mae: 0.3829 - val_loss: 0.3783 - val_mae: 0.3783\n",
      "Epoch 7/20\n",
      "3014/3014 [==============================] - 13s 4ms/step - loss: 0.3815 - mae: 0.3815 - val_loss: 0.3781 - val_mae: 0.3781\n",
      "Epoch 8/20\n",
      "3014/3014 [==============================] - 14s 5ms/step - loss: 0.3806 - mae: 0.3806 - val_loss: 0.3754 - val_mae: 0.3754\n",
      "Epoch 9/20\n",
      "3014/3014 [==============================] - 13s 4ms/step - loss: 0.3800 - mae: 0.3800 - val_loss: 0.3740 - val_mae: 0.3740\n",
      "Epoch 10/20\n",
      "3014/3014 [==============================] - 16s 5ms/step - loss: 0.3794 - mae: 0.3794 - val_loss: 0.3736 - val_mae: 0.3736\n",
      "Epoch 11/20\n",
      "3014/3014 [==============================] - 16s 5ms/step - loss: 0.3790 - mae: 0.3790 - val_loss: 0.3735 - val_mae: 0.3735\n",
      "Epoch 12/20\n",
      "3014/3014 [==============================] - 14s 5ms/step - loss: 0.3777 - mae: 0.3777 - val_loss: 0.3748 - val_mae: 0.3748\n",
      "Epoch 13/20\n",
      "3014/3014 [==============================] - 14s 5ms/step - loss: 0.3773 - mae: 0.3773 - val_loss: 0.3737 - val_mae: 0.3737\n",
      "Epoch 14/20\n",
      "3014/3014 [==============================] - 14s 5ms/step - loss: 0.3758 - mae: 0.3758 - val_loss: 0.3736 - val_mae: 0.3736\n",
      "Epoch 15/20\n",
      "3014/3014 [==============================] - 16s 5ms/step - loss: 0.3756 - mae: 0.3756 - val_loss: 0.3747 - val_mae: 0.3747\n",
      "Epoch 16/20\n",
      "3014/3014 [==============================] - 15s 5ms/step - loss: 0.3753 - mae: 0.3753 - val_loss: 0.3751 - val_mae: 0.3751\n",
      "Epoch 17/20\n",
      "3014/3014 [==============================] - 13s 4ms/step - loss: 0.3751 - mae: 0.3751 - val_loss: 0.3754 - val_mae: 0.3754\n",
      "Epoch 18/20\n",
      "3014/3014 [==============================] - 15s 5ms/step - loss: 0.3749 - mae: 0.3749 - val_loss: 0.3755 - val_mae: 0.3755\n",
      "Epoch 19/20\n",
      "3014/3014 [==============================] - 15s 5ms/step - loss: 0.3739 - mae: 0.3739 - val_loss: 0.3761 - val_mae: 0.3761\n",
      "Epoch 20/20\n",
      "3014/3014 [==============================] - 13s 4ms/step - loss: 0.3726 - mae: 0.3726 - val_loss: 0.3739 - val_mae: 0.3739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20b01d0730>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "model.fit(X.toarray(), Y, epochs=20, batch_size=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fbd8e47c-01ad-4649-bad5-6df824fee4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1593.620483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1755.819824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9094.369141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>8058.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>849.200195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         loss\n",
       "0   4  1593.620483\n",
       "1   6  1755.819824\n",
       "2   9  9094.369141\n",
       "3  12  8058.703125\n",
       "4  15   849.200195"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.exp(model.predict(xtest))-200\n",
    "submission['loss'] = preds\n",
    "submission.to_csv('../submissions/sub_cmplx_mlp_2.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1d3d7df5-017a-4b8e-8126-ce0fd7fb74a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "148/148 [==============================] - 4s 24ms/step - loss: 0.3697 - mae: 0.3697 - val_loss: 0.3738 - val_mae: 0.3738\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 6s 39ms/step - loss: 0.3668 - mae: 0.3668 - val_loss: 0.3734 - val_mae: 0.3734\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 4s 28ms/step - loss: 0.3651 - mae: 0.3651 - val_loss: 0.3725 - val_mae: 0.3725\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 6s 41ms/step - loss: 0.3649 - mae: 0.3649 - val_loss: 0.3727 - val_mae: 0.3727\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 5s 31ms/step - loss: 0.3636 - mae: 0.3636 - val_loss: 0.3722 - val_mae: 0.3722\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 5s 35ms/step - loss: 0.3629 - mae: 0.3629 - val_loss: 0.3722 - val_mae: 0.3722\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 5s 36ms/step - loss: 0.3626 - mae: 0.3626 - val_loss: 0.3727 - val_mae: 0.3727\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 4s 24ms/step - loss: 0.3616 - mae: 0.3616 - val_loss: 0.3728 - val_mae: 0.3728\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.3615 - mae: 0.3615 - val_loss: 0.3726 - val_mae: 0.3726\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 5s 35ms/step - loss: 0.3607 - mae: 0.3607 - val_loss: 0.3727 - val_mae: 0.3727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20985559d0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "model.fit(X.toarray(), Y, epochs=10, batch_size=1024, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "88d87ba0-b27a-4999-a90d-1f47663f485f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1480.357910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1785.122314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9858.220703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7311.822266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>842.061646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         loss\n",
       "0   4  1480.357910\n",
       "1   6  1785.122314\n",
       "2   9  9858.220703\n",
       "3  12  7311.822266\n",
       "4  15   842.061646"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.exp(model.predict(xtest))-200\n",
    "submission['loss'] = preds\n",
    "submission.to_csv('../submissions/sub_cmplx_mlp_3.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "871400e0-f33a-4d0d-b0fd-a366f0350a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 1.9232 - mae: 1.9232 - val_loss: 0.4756 - val_mae: 0.4756\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.4290 - mae: 0.4290 - val_loss: 0.4079 - val_mae: 0.4079\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.4007 - mae: 0.4007 - val_loss: 0.3989 - val_mae: 0.3989\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.3953 - mae: 0.3953 - val_loss: 0.3967 - val_mae: 0.3967\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.3936 - mae: 0.3936 - val_loss: 0.3961 - val_mae: 0.3961\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.3930 - mae: 0.3930 - val_loss: 0.3968 - val_mae: 0.3968\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.3928 - mae: 0.3928 - val_loss: 0.3959 - val_mae: 0.3959\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.3925 - mae: 0.3925 - val_loss: 0.3963 - val_mae: 0.3963\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.3931 - mae: 0.3931 - val_loss: 0.3976 - val_mae: 0.3976\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.3928 - mae: 0.3928 - val_loss: 0.3967 - val_mae: 0.3967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f209806d280>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "model.fit(X.toarray(), Y, epochs=10, batch_size=2048, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f6e14490-b21e-4152-843a-4c11ce3301df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.4007 - mae: 0.4007 - val_loss: 0.4196 - val_mae: 0.4196\n",
      "Epoch 2/10\n",
      "1177/1177 [==============================] - 2s 1ms/step - loss: 0.3997 - mae: 0.3997 - val_loss: 0.4180 - val_mae: 0.4180\n",
      "Epoch 3/10\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3987 - mae: 0.3987 - val_loss: 0.4043 - val_mae: 0.4043\n",
      "Epoch 4/10\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3980 - mae: 0.3980 - val_loss: 0.3987 - val_mae: 0.3987\n",
      "Epoch 5/10\n",
      "1177/1177 [==============================] - 2s 1ms/step - loss: 0.3987 - mae: 0.3987 - val_loss: 0.3995 - val_mae: 0.3995\n",
      "Epoch 6/10\n",
      "1177/1177 [==============================] - 2s 1ms/step - loss: 0.3977 - mae: 0.3977 - val_loss: 0.4009 - val_mae: 0.4009\n",
      "Epoch 7/10\n",
      "1177/1177 [==============================] - 2s 1ms/step - loss: 0.3973 - mae: 0.3973 - val_loss: 0.3939 - val_mae: 0.3939\n",
      "Epoch 8/10\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3882 - mae: 0.3882 - val_loss: 0.3875 - val_mae: 0.3875\n",
      "Epoch 9/10\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3853 - mae: 0.3853 - val_loss: 0.3870 - val_mae: 0.3870\n",
      "Epoch 10/10\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3851 - mae: 0.3851 - val_loss: 0.3883 - val_mae: 0.3883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f208460c490>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "model.fit(X.toarray(), Y, epochs=10, batch_size=128, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eec05355-7fb7-4d3b-80fc-2bd4d9020d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3848 - mae: 0.3848 - val_loss: 0.3862 - val_mae: 0.3862\n",
      "Epoch 2/20\n",
      "1177/1177 [==============================] - 2s 1ms/step - loss: 0.3838 - mae: 0.3838 - val_loss: 0.3843 - val_mae: 0.3843\n",
      "Epoch 3/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3839 - mae: 0.3839 - val_loss: 0.3864 - val_mae: 0.3864\n",
      "Epoch 4/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3839 - mae: 0.3839 - val_loss: 0.3853 - val_mae: 0.3853\n",
      "Epoch 5/20\n",
      "1177/1177 [==============================] - 2s 1ms/step - loss: 0.3827 - mae: 0.3827 - val_loss: 0.3871 - val_mae: 0.3871\n",
      "Epoch 6/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3820 - mae: 0.3820 - val_loss: 0.3868 - val_mae: 0.3868\n",
      "Epoch 7/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3813 - mae: 0.3813 - val_loss: 0.3838 - val_mae: 0.3838\n",
      "Epoch 8/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3816 - mae: 0.3816 - val_loss: 0.3830 - val_mae: 0.3830\n",
      "Epoch 9/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3808 - mae: 0.3808 - val_loss: 0.3820 - val_mae: 0.3820\n",
      "Epoch 10/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3805 - mae: 0.3805 - val_loss: 0.3887 - val_mae: 0.3887\n",
      "Epoch 11/20\n",
      "1177/1177 [==============================] - 2s 1ms/step - loss: 0.3794 - mae: 0.3794 - val_loss: 0.3822 - val_mae: 0.3822\n",
      "Epoch 12/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3794 - mae: 0.3794 - val_loss: 0.3848 - val_mae: 0.3848\n",
      "Epoch 13/20\n",
      "1177/1177 [==============================] - 2s 1ms/step - loss: 0.3791 - mae: 0.3791 - val_loss: 0.3825 - val_mae: 0.3825\n",
      "Epoch 14/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3785 - mae: 0.3785 - val_loss: 0.3819 - val_mae: 0.3819\n",
      "Epoch 15/20\n",
      "1177/1177 [==============================] - 3s 2ms/step - loss: 0.3787 - mae: 0.3787 - val_loss: 0.3831 - val_mae: 0.3831\n",
      "Epoch 16/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3786 - mae: 0.3786 - val_loss: 0.3826 - val_mae: 0.3826\n",
      "Epoch 17/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3782 - mae: 0.3782 - val_loss: 0.4034 - val_mae: 0.4034\n",
      "Epoch 18/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3779 - mae: 0.3779 - val_loss: 0.3815 - val_mae: 0.3815\n",
      "Epoch 19/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3773 - mae: 0.3773 - val_loss: 0.3829 - val_mae: 0.3829\n",
      "Epoch 20/20\n",
      "1177/1177 [==============================] - 2s 2ms/step - loss: 0.3780 - mae: 0.3780 - val_loss: 0.3866 - val_mae: 0.3866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20844ec520>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "model.fit(X.toarray(), Y, epochs=20, batch_size=128, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4cb2ef0d-a114-4f27-b19d-c77ccb9ccf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.7991 - val_loss: 8.6658\n",
      "Epoch 2/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.8002 - val_loss: 8.6553\n",
      "Epoch 3/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.7957 - val_loss: 8.4956\n",
      "Epoch 4/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7919 - val_loss: 8.3869\n",
      "Epoch 5/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7835 - val_loss: 8.3396\n",
      "Epoch 6/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.7817 - val_loss: 8.3201\n",
      "Epoch 7/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.7791 - val_loss: 8.3120\n",
      "Epoch 8/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7745 - val_loss: 8.3067\n",
      "Epoch 9/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7713 - val_loss: 8.2944\n",
      "Epoch 10/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7663 - val_loss: 8.2925\n",
      "Epoch 11/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.7597 - val_loss: 8.2902\n",
      "Epoch 12/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7567 - val_loss: 8.2878\n",
      "Epoch 13/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7474 - val_loss: 8.2856\n",
      "Epoch 14/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7454 - val_loss: 8.2784\n",
      "Epoch 15/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.7392 - val_loss: 8.2722\n",
      "Epoch 16/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7348 - val_loss: 8.2694\n",
      "Epoch 17/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7277 - val_loss: 8.2601\n",
      "Epoch 18/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7232 - val_loss: 8.2523\n",
      "Epoch 19/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.7139 - val_loss: 8.2484\n",
      "Epoch 20/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.7102 - val_loss: 8.2420\n",
      "Epoch 21/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.7042 - val_loss: 8.2379\n",
      "Epoch 22/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.7008 - val_loss: 8.2330\n",
      "Epoch 23/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.6903 - val_loss: 8.2278\n",
      "Epoch 24/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.6842 - val_loss: 8.2146\n",
      "Epoch 25/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.6760 - val_loss: 8.2118\n",
      "Epoch 26/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.6720 - val_loss: 8.2015\n",
      "Epoch 27/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.6601 - val_loss: 8.1968\n",
      "Epoch 28/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.6563 - val_loss: 8.1951\n",
      "Epoch 29/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.6467 - val_loss: 8.1805\n",
      "Epoch 30/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.6417 - val_loss: 8.1692\n",
      "Epoch 31/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.6316 - val_loss: 8.1635\n",
      "Epoch 32/100\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 7.6240 - val_loss: 8.1621\n",
      "Epoch 33/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.6137 - val_loss: 8.1472\n",
      "Epoch 34/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.6067 - val_loss: 8.1364\n",
      "Epoch 35/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.5975 - val_loss: 8.1360\n",
      "Epoch 36/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.5891 - val_loss: 8.1274\n",
      "Epoch 37/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.5802 - val_loss: 8.1230\n",
      "Epoch 38/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.5717 - val_loss: 8.1160\n",
      "Epoch 39/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.5656 - val_loss: 8.1030\n",
      "Epoch 40/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.5518 - val_loss: 8.0969\n",
      "Epoch 41/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.5435 - val_loss: 8.0838\n",
      "Epoch 42/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.5339 - val_loss: 8.0714\n",
      "Epoch 43/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.5256 - val_loss: 8.0656\n",
      "Epoch 44/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.5185 - val_loss: 8.0536\n",
      "Epoch 45/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.5089 - val_loss: 8.0428\n",
      "Epoch 46/100\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 7.4962 - val_loss: 8.0447\n",
      "Epoch 47/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.4915 - val_loss: 8.0351\n",
      "Epoch 48/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.4813 - val_loss: 8.0213\n",
      "Epoch 49/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.4688 - val_loss: 8.0092\n",
      "Epoch 50/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.4556 - val_loss: 8.0052\n",
      "Epoch 51/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.4447 - val_loss: 7.9969\n",
      "Epoch 52/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.4377 - val_loss: 7.9800\n",
      "Epoch 53/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.4236 - val_loss: 7.9750\n",
      "Epoch 54/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.4138 - val_loss: 7.9595\n",
      "Epoch 55/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.4074 - val_loss: 7.9546\n",
      "Epoch 56/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.3900 - val_loss: 7.9406\n",
      "Epoch 57/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.3790 - val_loss: 7.9281\n",
      "Epoch 58/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.3693 - val_loss: 7.9151\n",
      "Epoch 59/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.3607 - val_loss: 7.9064\n",
      "Epoch 60/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.3467 - val_loss: 7.8969\n",
      "Epoch 61/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.3337 - val_loss: 7.8885\n",
      "Epoch 62/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.3209 - val_loss: 7.8782\n",
      "Epoch 63/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.3106 - val_loss: 7.8618\n",
      "Epoch 64/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.2928 - val_loss: 7.8510\n",
      "Epoch 65/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.2837 - val_loss: 7.8384\n",
      "Epoch 66/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.2725 - val_loss: 7.8300\n",
      "Epoch 67/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.2554 - val_loss: 7.8150\n",
      "Epoch 68/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.2429 - val_loss: 7.8089\n",
      "Epoch 69/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.2302 - val_loss: 7.8006\n",
      "Epoch 70/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.2197 - val_loss: 7.7777\n",
      "Epoch 71/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.2084 - val_loss: 7.7670\n",
      "Epoch 72/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.1915 - val_loss: 7.7531\n",
      "Epoch 73/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.1773 - val_loss: 7.7361\n",
      "Epoch 74/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.1649 - val_loss: 7.7286\n",
      "Epoch 75/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.1483 - val_loss: 7.7155\n",
      "Epoch 76/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 7.1351 - val_loss: 7.7001\n",
      "Epoch 77/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.1200 - val_loss: 7.6886\n",
      "Epoch 78/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.1052 - val_loss: 7.6773\n",
      "Epoch 79/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.0898 - val_loss: 7.6643\n",
      "Epoch 80/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.0742 - val_loss: 7.6479\n",
      "Epoch 81/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.0583 - val_loss: 7.6321\n",
      "Epoch 82/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.0427 - val_loss: 7.6229\n",
      "Epoch 83/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 7.0253 - val_loss: 7.6074\n",
      "Epoch 84/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 7.0111 - val_loss: 7.5915\n",
      "Epoch 85/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.9928 - val_loss: 7.5721\n",
      "Epoch 86/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.9756 - val_loss: 7.5607\n",
      "Epoch 87/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 6.9617 - val_loss: 7.5458\n",
      "Epoch 88/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.9489 - val_loss: 7.5302\n",
      "Epoch 89/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.9291 - val_loss: 7.5184\n",
      "Epoch 90/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 6.9103 - val_loss: 7.4971\n",
      "Epoch 91/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 6.8935 - val_loss: 7.4857\n",
      "Epoch 92/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.8731 - val_loss: 7.4731\n",
      "Epoch 93/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 6.8586 - val_loss: 7.4554\n",
      "Epoch 94/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 6.8364 - val_loss: 7.4328\n",
      "Epoch 95/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.8225 - val_loss: 7.4240\n",
      "Epoch 96/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.8005 - val_loss: 7.3988\n",
      "Epoch 97/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.7855 - val_loss: 7.3864\n",
      "Epoch 98/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.7649 - val_loss: 7.3658\n",
      "Epoch 99/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.7427 - val_loss: 7.3492\n",
      "Epoch 100/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 6.7248 - val_loss: 7.3305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20b02d5bb0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn_model()\n",
    "model.fit(X.toarray(), Y, epochs=100, batch_size=1000, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "534d45e8-1b9f-4cb3-9e63-5e7f3e1be468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 6.6149 - val_loss: 7.1497\n",
      "Epoch 2/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 6.4170 - val_loss: 6.9701\n",
      "Epoch 3/100\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 6.2060 - val_loss: 6.7641\n",
      "Epoch 4/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 5.9811 - val_loss: 6.5320\n",
      "Epoch 5/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 5.7430 - val_loss: 6.2799\n",
      "Epoch 6/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 5.4865 - val_loss: 6.0372\n",
      "Epoch 7/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 5.2174 - val_loss: 5.7502\n",
      "Epoch 8/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 4.9248 - val_loss: 5.4940\n",
      "Epoch 9/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 4.6160 - val_loss: 5.1457\n",
      "Epoch 10/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 4.2991 - val_loss: 4.8094\n",
      "Epoch 11/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 3.9706 - val_loss: 4.4496\n",
      "Epoch 12/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 3.6401 - val_loss: 4.0908\n",
      "Epoch 13/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 3.3148 - val_loss: 3.6968\n",
      "Epoch 14/100\n",
      "1507/1507 [==============================] - 9s 6ms/step - loss: 3.0088 - val_loss: 3.3579\n",
      "Epoch 15/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 2.7343 - val_loss: 2.9981\n",
      "Epoch 16/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 2.4905 - val_loss: 2.6877\n",
      "Epoch 17/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 2.2878 - val_loss: 2.4259\n",
      "Epoch 18/100\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 2.1339 - val_loss: 2.2023\n",
      "Epoch 19/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 2.0160 - val_loss: 2.0093\n",
      "Epoch 20/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 1.9174 - val_loss: 1.8400\n",
      "Epoch 21/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 1.8416 - val_loss: 1.7178\n",
      "Epoch 22/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 1.7799 - val_loss: 1.5934\n",
      "Epoch 23/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.7345 - val_loss: 1.5176\n",
      "Epoch 24/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.6871 - val_loss: 1.4257\n",
      "Epoch 25/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 1.6529 - val_loss: 1.3592\n",
      "Epoch 26/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.6235 - val_loss: 1.3026\n",
      "Epoch 27/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.5882 - val_loss: 1.2579\n",
      "Epoch 28/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.5666 - val_loss: 1.1905\n",
      "Epoch 29/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.5428 - val_loss: 1.1555\n",
      "Epoch 30/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.5165 - val_loss: 1.1147\n",
      "Epoch 31/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.5026 - val_loss: 1.0811\n",
      "Epoch 32/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 1.4829 - val_loss: 1.0454\n",
      "Epoch 33/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.4694 - val_loss: 1.0243\n",
      "Epoch 34/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.4524 - val_loss: 0.9913\n",
      "Epoch 35/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 1.4349 - val_loss: 0.9747\n",
      "Epoch 36/100\n",
      "1507/1507 [==============================] - 5s 4ms/step - loss: 1.4263 - val_loss: 0.9502\n",
      "Epoch 37/100\n",
      "1507/1507 [==============================] - 7s 5ms/step - loss: 1.4133 - val_loss: 0.9325\n",
      "Epoch 38/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.3966 - val_loss: 0.9072\n",
      "Epoch 39/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.3847 - val_loss: 0.8972\n",
      "Epoch 40/100\n",
      "1507/1507 [==============================] - 5s 4ms/step - loss: 1.3728 - val_loss: 0.8819\n",
      "Epoch 41/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.3633 - val_loss: 0.8706\n",
      "Epoch 42/100\n",
      "1507/1507 [==============================] - 5s 4ms/step - loss: 1.3568 - val_loss: 0.8543\n",
      "Epoch 43/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.3423 - val_loss: 0.8470\n",
      "Epoch 44/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 1.3339 - val_loss: 0.8381\n",
      "Epoch 45/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 1.3238 - val_loss: 0.8283\n",
      "Epoch 46/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.3111 - val_loss: 0.8160\n",
      "Epoch 47/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.3087 - val_loss: 0.8006\n",
      "Epoch 48/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.2995 - val_loss: 0.7999\n",
      "Epoch 49/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.2897 - val_loss: 0.7832\n",
      "Epoch 50/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 1.2788 - val_loss: 0.7872\n",
      "Epoch 51/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.2727 - val_loss: 0.7689\n",
      "Epoch 52/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.2645 - val_loss: 0.7710\n",
      "Epoch 53/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.2616 - val_loss: 0.7598\n",
      "Epoch 54/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 1.2511 - val_loss: 0.7527\n",
      "Epoch 55/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.2459 - val_loss: 0.7440\n",
      "Epoch 56/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.2341 - val_loss: 0.7378\n",
      "Epoch 57/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.2299 - val_loss: 0.7292\n",
      "Epoch 58/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.2237 - val_loss: 0.7190\n",
      "Epoch 59/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.2187 - val_loss: 0.7190\n",
      "Epoch 60/100\n",
      "1507/1507 [==============================] - 5s 4ms/step - loss: 1.2064 - val_loss: 0.7126\n",
      "Epoch 61/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.2059 - val_loss: 0.7053\n",
      "Epoch 62/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1984 - val_loss: 0.7031\n",
      "Epoch 63/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 1.1942 - val_loss: 0.7046\n",
      "Epoch 64/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.1886 - val_loss: 0.6938\n",
      "Epoch 65/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1785 - val_loss: 0.6970\n",
      "Epoch 66/100\n",
      "1507/1507 [==============================] - 7s 4ms/step - loss: 1.1775 - val_loss: 0.6873\n",
      "Epoch 67/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1687 - val_loss: 0.6851\n",
      "Epoch 68/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1673 - val_loss: 0.6764\n",
      "Epoch 69/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.1582 - val_loss: 0.6731\n",
      "Epoch 70/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.1511 - val_loss: 0.6716\n",
      "Epoch 71/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.1519 - val_loss: 0.6630\n",
      "Epoch 72/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1470 - val_loss: 0.6584\n",
      "Epoch 73/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1385 - val_loss: 0.6547\n",
      "Epoch 74/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.1338 - val_loss: 0.6511\n",
      "Epoch 75/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.1313 - val_loss: 0.6481\n",
      "Epoch 76/100\n",
      "1507/1507 [==============================] - 5s 4ms/step - loss: 1.1233 - val_loss: 0.6479\n",
      "Epoch 77/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.1246 - val_loss: 0.6438\n",
      "Epoch 78/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1131 - val_loss: 0.6375\n",
      "Epoch 79/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.1123 - val_loss: 0.6375\n",
      "Epoch 80/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1051 - val_loss: 0.6303\n",
      "Epoch 81/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1021 - val_loss: 0.6333\n",
      "Epoch 82/100\n",
      "1507/1507 [==============================] - 6s 4ms/step - loss: 1.1002 - val_loss: 0.6295\n",
      "Epoch 83/100\n",
      "1507/1507 [==============================] - 5s 4ms/step - loss: 1.0967 - val_loss: 0.6210\n",
      "Epoch 84/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.0909 - val_loss: 0.6186\n",
      "Epoch 85/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.0875 - val_loss: 0.6155\n",
      "Epoch 86/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.0838 - val_loss: 0.6119\n",
      "Epoch 87/100\n",
      "1507/1507 [==============================] - 5s 3ms/step - loss: 1.0785 - val_loss: 0.6117\n",
      "Epoch 88/100\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 1.0764 - val_loss: 0.6088\n",
      "Epoch 89/100\n",
      "1507/1507 [==============================] - 8s 5ms/step - loss: 1.0731 - val_loss: 0.6074\n",
      "Epoch 90/100\n",
      "1507/1507 [==============================] - 9s 6ms/step - loss: 1.0704 - val_loss: 0.6025\n",
      "Epoch 91/100\n",
      "1507/1507 [==============================] - 9s 6ms/step - loss: 1.0609 - val_loss: 0.6019\n",
      "Epoch 92/100\n",
      "1507/1507 [==============================] - 10s 7ms/step - loss: 1.0615 - val_loss: 0.6062\n",
      "Epoch 93/100\n",
      "1507/1507 [==============================] - 9s 6ms/step - loss: 1.0578 - val_loss: 0.5932\n",
      "Epoch 94/100\n",
      "1507/1507 [==============================] - 9s 6ms/step - loss: 1.0510 - val_loss: 0.5908\n",
      "Epoch 95/100\n",
      "1507/1507 [==============================] - 9s 6ms/step - loss: 1.0559 - val_loss: 0.5941\n",
      "Epoch 96/100\n",
      "1507/1507 [==============================] - 10s 6ms/step - loss: 1.0457 - val_loss: 0.5867\n",
      "Epoch 97/100\n",
      "1507/1507 [==============================] - 9s 6ms/step - loss: 1.0408 - val_loss: 0.5856\n",
      "Epoch 98/100\n",
      "1507/1507 [==============================] - 10s 6ms/step - loss: 1.0424 - val_loss: 0.5850\n",
      "Epoch 99/100\n",
      "1507/1507 [==============================] - 10s 7ms/step - loss: 1.0427 - val_loss: 0.5793\n",
      "Epoch 100/100\n",
      "1507/1507 [==============================] - 9s 6ms/step - loss: 1.0303 - val_loss: 0.5811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20505c55b0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X.toarray(), Y, epochs=100, batch_size=100, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b0ff6-b02c-4b37-a5ff-259f5f87c88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
